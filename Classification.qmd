---
title: "Multi-level classification"
format: pdf
editor: visual
---

## Creating the dictionary

```{r, warning=FALSE, message=FALSE}
library(quanteda)
library(stringr)
library(textstem)
library(lexicon)
library(readr)
library(purrr)
library(dplyr)
library(tidyr)
```

```{r}
# Loading the data
dict <- read.csv(
  "Codebook.csv",
  sep = ";",
  stringsAsFactors = FALSE
)
colnames(dict) <- c("level0", "level1", "level2_3", "keywords")
```

```{r}
# Cleaning the keywords
dict$keywords <- tolower(dict$keywords)
dict$keywords <- str_replace_all(dict$keywords, "\\bc\\b", "celsius") 
dict$keywords <- str_replace_all(dict$keywords, "colonization of mars", "colonization, mars")
dict$keywords <- str_replace_all(dict$keywords, "the paris climate agreement", "paris climate agreement")

# Lemmatizing
dict$keywords_list <- lapply(strsplit(dict$keywords, ","), trimws)
dict$keywords_list <- lapply(dict$keywords_list, lemmatize_words)

library(SnowballC)
dict$keywords_stem <- lapply(dict$keywords_list, function(x) {
  sapply(x, function(term) {
    if (str_detect(term, "\\s")) {
      NA_character_     
    } else {
      wordStem(term)
    }
  }, USE.NAMES = FALSE) |> na.omit()
})
```

## Check with 200 initially labelled posts

```{r}
manual_df <- read.csv(
  "manual_200.csv",
  sep = ";"
)
```

```{r}
dict_level2_3 <- dict$level2_3 %>% unique()
manual_labels <- unique(manual_df$Level2_3)
missing_labels <- manual_labels[!(manual_labels %in% dict_level2_3)]

if(length(missing_labels) == 0) {
  message("All manual Level2_3 categories exist in the dictionary âœ…")
} else {
  message("The following manual Level2_3 categories are missing in the dictionary:")
  print(missing_labels)
}
```

```{r}
assign_dict_category <- function(text, dict) {
  text_raw  <- tolower(str_squish(text))
  text_stem <- paste(wordStem(unlist(strsplit(text_raw, "\\s+"))), collapse = " ")

  
  matches <- sapply(seq_len(nrow(dict)), function(i) {
    raw_hit <- any(str_detect(
      text_raw,
      paste0("\\b(", paste(dict$keywords_list[[i]], collapse = "|"), ")\\b")
    ))
    stem_hit <- length(dict$keywords_stem[[i]]) > 0 &&
      any(str_detect(
        text_stem,
        paste0("\\b(", paste(dict$keywords_stem[[i]], collapse = "|"), ")\\b")
      ))
    raw_hit || stem_hit
  })

  matched_categories <- dict$level2_3[matches]
  if ("Unclassifiable" %in% matched_categories && length(matched_categories) > 1) {
  matched_categories <- setdiff(matched_categories, "Unclassifiable")
}
  if (length(matched_categories) == 0) return(NA)
  paste(matched_categories, collapse = "; ")
}

library(dplyr)
manual_df <- manual_df %>%
  rowwise() %>%
  mutate(dict_category = list(assign_dict_category(selftext, dict)))
```

```{r}
manual_df <- manual_df %>%
  rowwise() %>%
  mutate(
    dict_vec = list(strsplit(dict_category, ";\\s*")[[1]]),
    match = Level2_3 %in% trimws(unlist(dict_vec))
  ) %>%
  ungroup()
```

```{r}
n_correct <- sum(manual_df$match, na.rm = TRUE)
n_total <- nrow(manual_df)
accuracy <- n_correct / n_total

cat("Correct predictions on level 2:", n_correct, "\n")
cat("Total texts:", n_total, "\n")
cat("Overall accuracy:", round(accuracy * 100, 2), "%\n")
```

```{r}
level2_to_level1 <- setNames(dict$level1, dict$level2_3)
manual_df <- manual_df %>%
  rowwise() %>%
  mutate(
    manual_level1 = setNames(dict$level1, dict$level2_3)[Level2_3],
    predicted_level1 = list(
      unique(level2_to_level1[strsplit(dict_category, ";\\s*")[[1]]])
    ),
    match_level1 = manual_level1 %in% trimws(unlist(predicted_level1))
  ) %>%
  ungroup()

level1_accuracy <- mean(manual_df$match_level1, na.rm = TRUE)
level1_accuracy
```

## Apply to full dataset

```{r}
full_df <- read.csv('r_collapse_posts.csv')
```

```{r}
full_df <- full_df[
  !is.na(full_df$selftext) &
  full_df$selftext != "" &
  full_df$selftext != "[removed]" &
  full_df$selftext != "[deleted]",
]
```

```{r}
full_df$dict_category <- sapply(full_df$selftext, assign_dict_category, dict = dict)

full_df$dict_level1 <- sapply(full_df$dict_category, function(x) {
  level2s <- trimws(strsplit(x, ";\\s*")[[1]])
  unique(level2_to_level1[level2s])
})
```

```{r}
library(tidyr)
level2_long <- full_df %>%
  mutate(dict_category = str_squish(dict_category)) %>%  
  separate_rows(dict_category, sep = ";\\s*") %>%
  filter(!is.na(dict_category))

level2_counts <- level2_long %>%
  count(dict_category, sort = TRUE)
```

```{r}
library(ggplot2)

ggplot(level2_counts, aes(x = reorder(dict_category, n), y = n)) +
  geom_col(fill = "coral") +
  coord_flip() +
  labs(
    x = "Level-2 (and 3) categories",
    y = "Number of posts",
    title = "Distribution of level-2 categories"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
level2_long <- full_df %>%
  mutate(dict_category = str_squish(dict_category)) %>%
  separate_rows(dict_category, sep = ";\\s*") %>%
  filter(!is.na(dict_category)) %>%
  mutate(
    level1 = level2_to_level1[dict_category]
  )

level2_counts <- level2_long %>%
  count(dict_category, level1, sort = TRUE)

level1_order <- level2_counts %>%
  arrange(desc(n)) %>%    
  pull(level1) %>%
  unique()

level2_counts$level1 <- factor(level2_counts$level1, levels = level1_order)

level1_colors <- c(
  "Environment"        = "#66A61E", 
  "Human Response"     = "#D95F02",
  "Economy"            = "#7570B3",
  "Society & Politics"  = "#E7298A",
  "Technology"         = "#1B9E77",
  "Disaster"          = "darkred",
  "Unclassifiable"     = "grey70"
)

library(ggplot2)

ggplot(level2_counts,
       aes(x = reorder(dict_category, n),
           y = n,
           fill = level1)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = level1_colors) +
  labs(
    x = "Level-2 category",
    y = "Number of posts",
    fill = "Level-1 category",
    title = "Distribution of level-2 categories"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
level1_long <- full_df %>%
  unnest(dict_level1) %>%      
  mutate(
    level1 = str_squish(dict_level1)
  ) %>%
  filter(!is.na(level1))

level1_counts <- level1_long %>%
  count(dict_level1, sort = TRUE)

level1_order <- level1_counts %>%
  pull(dict_level1)

level1_counts$dict_level1 <- factor(
  level1_counts$dict_level1,
  levels = level1_order
)

ggplot(level1_counts,
       aes(x = dict_level1, y = n, fill = dict_level1)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = level1_colors) +
  labs(
    x = "Level-1 category",
    y = "Number of posts",
    fill = "Level-1 category",
    title = "Distribution of level-1 categories"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")

```

```{r}
level2_long <- full_df %>%
  mutate(dict_category = str_squish(dict_category)) %>%
  separate_rows(dict_category, sep = ";\\s*") %>%
  filter(!is.na(dict_category)) %>%
  mutate(
    level1 = level2_to_level1[dict_category]
  )

level2_counts <- level2_long %>%
  count(dict_category, level1, sort = TRUE)

level1_order <- level2_counts %>%
  arrange(desc(n)) %>%    
  pull(level1) %>%
  unique()

level2_counts$level1 <- factor(level2_counts$level1, levels = level1_order)

level1_colors <- c(
  "Environment"        = "grey70", 
  "Human Response"     = "#D95F02",
  "Economy"            = "grey70",
  "Society & Politics"  = "grey70",
  "Technology"         = "grey70",
  "Disaster"          = "grey70",
  "Unclassifiable"     = "#D95F02"
)

library(ggplot2)

ggplot(level2_counts,
       aes(x = reorder(dict_category, n),
           y = n,
           fill = level1)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = level1_colors) +
  labs(
    x = "Level-2 category",
    y = "Number of posts",
    fill = "Level-1 category",
    title = "Non-risk topics (orange)"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
level2_long <- full_df %>%
  filter(!is.na(dict_category)) %>%
  separate_rows(dict_category, sep = ";\\s*") %>%
  mutate(level2 = str_squish(dict_category))

nodes <- level2_long %>%
  count(level2, name = "freq") %>%
  mutate(
    level1 = level2_to_level1[level2]
  )
```

## Validate with 200 additional manually coded posts

```{r, message=FALSE}
val_data <- read_csv2(
  "additional200.csv",
  locale = locale(encoding = "UTF-8")
)
val_data <- val_data[, c("Post number", "Text", "Category 1(manual)", "Category 2(manual)", "Category 3(manual)", "Category 4(manual)", "Category 5(manual)")]
colnames(val_data) <- c("id", "text", "category1", "category2", "category3", "category4", "category5")
val_data <- val_data[-201,]
```

```{r}
val_data$text <- iconv(val_data$text, from = "UTF-8", to = "UTF-8", sub = "byte")
val_data$text_clean <- tolower(val_data$text)
val_data$text_stem <- sapply(val_data$text_clean, function(x) {
  paste(wordStem(unlist(strsplit(x, "\\s+"))), collapse = " ")
})
```

```{r}
match_keywords <- function(text, keywords_list) {
  any(sapply(keywords_list, function(k) grepl(paste0("\\b", k, "\\b"), text, ignore.case = TRUE)))
}

get_matched_categories <- function(text, dict_keywords, dict_categories) {
  matches <- dict_categories[sapply(dict_keywords, function(k) match_keywords(text, k))]
  return(matches)
}
```

```{r}
val_data$pred_categories <- sapply(val_data$text_clean, function(txt) {
  get_matched_categories(txt, dict$keywords_list, dict$level2_3)
})

val_data$pred_categories_stem <- sapply(val_data$text_stem, function(txt) {
  get_matched_categories(txt, dict$keywords_stem, dict$level2_3)
})

val_data$pred_categories_combined <- mapply(function(nonstem, stem) {
  unique(c(nonstem, stem))
}, val_data$pred_categories, val_data$pred_categories_stem, SIMPLIFY = FALSE)

val_data$pred_categories_combined <- lapply(val_data$pred_categories, function(pred) {
  if (length(pred) == 0) {
    "Unclassifiable"
  } else {
    pred
  }
})
```

```{r}
val_data$manual_categories <- pmap(val_data[, c("category1","category2","category3","category4","category5")], ~ c(...)) %>%
  map(~ .[!is.na(.)])

val_data$manual_categories <- lapply(val_data$manual_categories, function(m) {
  m <- m[!is.na(m)] 
  m <- m[m != "?"]      
  if (length(m) == 0) {
    "Unclassifiable"
  } else {
    m
  }
})

validate_match <- function(manual, predicted) {
  list(
    all_match = all(predicted %in% manual) & length(predicted) == length(manual),
    any_match = any(predicted %in% manual),
    level1_match = any(sapply(predicted, function(p) any(dict$level1[dict$level2_3 == p] %in% dict$level1[dict$level2_3 %in% manual])))
  )
}
```

```{r}
val_results <- mapply(validate_match, val_data$manual_categories, val_data$pred_categories_combined, SIMPLIFY = FALSE)

val_data <- cbind(val_data, do.call(rbind, lapply(val_results, as.data.frame)))
```

```{r}
num_all_match <- sum(val_data$all_match)
num_any_match <- sum(val_data$any_match)
num_level1_match <- sum(val_data$level1_match)


total_posts <- nrow(val_data)


cat("Validation summary:\n")
cat("Total posts:", total_posts, "\n")
cat("All labels match:", num_all_match, "(", round(num_all_match/total_posts*100, 1), "%)\n")
cat("At least one label matches:", num_any_match, "(", round(num_any_match/total_posts*100, 1), "%)\n")
cat("Level 1 match:", num_level1_match, "(", round(num_level1_match/total_posts*100, 1), "%)\n")
```

### Calculate lift

```{r}
pred_long <- val_data %>%
  select(id, pred_categories_combined) %>%
  unnest(cols = c(pred_categories_combined)) %>%
  rename(predicted = pred_categories_combined)

manual_long <- val_data %>%
  select(id, manual_categories) %>%
  rename(manual = manual_categories)

pred_long <- pred_long %>%
  left_join(manual_long, by = "id") %>%
  rowwise() %>%
  mutate(correct = predicted %in% manual) %>%
  ungroup()
```

```{r}
category_lift <- pred_long %>%
  group_by(predicted) %>%
  summarise(
    correct_pred = sum(correct),
    total_pred = n()
  ) %>%
  ungroup()

baseline <- val_data %>%
  unnest(cols = c(manual_categories)) %>%
  group_by(manual_categories) %>%
  summarise(manual_count = n()) %>%
  mutate(baseline_prob = manual_count / nrow(val_data))

category_lift <- category_lift %>%
  left_join(baseline, by = c("predicted" = "manual_categories")) %>%
  mutate(
    precision = correct_pred / total_pred,
    lift = precision / baseline_prob
  ) %>%
  arrange(desc(lift))

category_lift
```
